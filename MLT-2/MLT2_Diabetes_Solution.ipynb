{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3788227-721c-42cf-b5f9-5536f3d35646",
   "metadata": {},
   "source": [
    "<img src=\"https://cellstrat2.s3.amazonaws.com/PlatformAssets/bluewhitelogo.svg\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "# ML Tuesdays - Session 2\n",
    "## Machine Learning Track\n",
    "### Diabetes Classification Exercise (Solution)\n",
    "\n",
    "### Guidelines\n",
    "1. The notebook has been split into multiple steps with fine-grained instructions for each step. Use the instructions for each code cell to complete the code.\n",
    "2. You can refer the Logistic Regression Module in the Machine Learning Pack from CellStrat Hub.\n",
    "3. Make use of the docstrings of the functions and classes using the `shift+tab` shortcut key.\n",
    "4. Refer the internet for the explanation of any algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a44b5-48a3-488e-bfb6-66259383cb88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## About the Dataset\n",
    "The Pima Indians Diabetes Dataset involves predicting the onset of diabetes within 5 years in Pima Indians given medical details.\n",
    "\n",
    "It is a binary (2-class) classification problem. The number of observations for each class is not balanced. There are 768 observations with 8 input variables and 1 output variable. Missing values are believed to be encoded with zero values. The variable names are as follows:\n",
    "\n",
    "- Number of times pregnant.\n",
    "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
    "- Diastolic blood pressure (mm Hg).\n",
    "- Triceps skinfold thickness (mm).\n",
    "- 2-Hour serum insulin (mu U/ml).\n",
    "- Body mass index (weight in kg/(height in m)^2).\n",
    "- Diabetes pedigree function.\n",
    "- Age (years).\n",
    "- Class variable (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f779463e-5f4e-4e70-b65f-7fc03b7c25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f0cadf-06e6-4ba3-ad2f-511147f0252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcd651c-b043-4504-92ea-d79489f823dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4fad2-3019-4dcd-a43c-89e74d94f527",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. Split to X and y data\n",
    "2. Perform Train Test Split\n",
    "3. Feature Scaling (Use Standard or Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ad143f0-eae2-4a29-9c5d-6b9c40e3abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = dataset.iloc[:, :-1]\n",
    "y_data = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f89584b-87e7-4d22-873e-63a52abb98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7d588a-19ba-4a0f-b2a1-934ac709dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4818cd63-32c6-478a-a0fe-26505fb6ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b498b72-cc9b-413a-a2cb-afeabe062343",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0158a4e-3f89-41c4-b12b-eea576f64a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e825f0a-f715-47fa-93b0-5b10000566ff",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "You need to train 4 different models i.e.,\n",
    "1. LogisticRegression\n",
    "2. K Nearest Neighbours (KNN)\n",
    "3. Decision Tree\n",
    "4. Random Forest\n",
    "\n",
    "Make optimal use of the scikit-learn documentation and google to understand each algorithm and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5a55c38-09ee-4a47-a113-1ec2bb94c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa151d0f-3a6d-4768-b7a4-3c67db71de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "tree_model = DecisionTreeClassifier()\n",
    "forest_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48dffa70-0c8a-4456-9ebb-00719c758f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72308ef4-73f3-4e45-a674-84c465eecbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "627c7bb9-4564-4370-84d2-ab2a9231c796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e50b93cc-a4e1-452a-bd9f-74d034d82fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679637a1-708c-4bff-9482-5a287b2b0ece",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "1. Evaluate the results of each model using the `classification_report` function in `sklearn.metrics`.\n",
    "2. Check which model has the best results on the train and test set.\n",
    "3. Have some models overfitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35921232-f968-4b1a-b46f-4fb066996fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "363c08db-3bb2-4a3d-9870-aa4bd44fd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    return classification_report(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42b6a976-7691-4799-bdbd-4993b6238dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results with Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       393\n",
      "           1       0.71      0.57      0.64       221\n",
      "\n",
      "    accuracy                           0.76       614\n",
      "   macro avg       0.75      0.72      0.73       614\n",
      "weighted avg       0.76      0.76      0.76       614\n",
      "\n",
      "\n",
      "Test Results with Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       107\n",
      "           1       0.76      0.62      0.68        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.80      0.77      0.78       154\n",
      "weighted avg       0.82      0.82      0.82       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Results with Logistic Regression')\n",
    "print(evaluate(logistic_model, X_train, y_train))\n",
    "\n",
    "print('\\nTest Results with Logistic Regression')\n",
    "print(evaluate(logistic_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "989d4ec2-4a0b-484d-91d2-96e3a8b08170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results with KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       393\n",
      "           1       0.77      0.67      0.72       221\n",
      "\n",
      "    accuracy                           0.81       614\n",
      "   macro avg       0.80      0.78      0.79       614\n",
      "weighted avg       0.81      0.81      0.81       614\n",
      "\n",
      "\n",
      "Test Results with KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       107\n",
      "           1       0.68      0.64      0.66        47\n",
      "\n",
      "    accuracy                           0.80       154\n",
      "   macro avg       0.76      0.75      0.76       154\n",
      "weighted avg       0.80      0.80      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Results with KNN')\n",
    "print(evaluate(knn, X_train, y_train))\n",
    "\n",
    "print('\\nTest Results with KNN')\n",
    "print(evaluate(knn, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a45f8f07-b308-437a-99c2-7c88fd817bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results with Decision Tree Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       393\n",
      "           1       1.00      1.00      1.00       221\n",
      "\n",
      "    accuracy                           1.00       614\n",
      "   macro avg       1.00      1.00      1.00       614\n",
      "weighted avg       1.00      1.00      1.00       614\n",
      "\n",
      "\n",
      "Test Results with Decision Tree Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       107\n",
      "           1       0.59      0.64      0.61        47\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.71      0.72      0.72       154\n",
      "weighted avg       0.76      0.75      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Results with Decision Tree Classifier')\n",
    "print(evaluate(tree_model, X_train, y_train))\n",
    "\n",
    "print('\\nTest Results with Decision Tree Classifier')\n",
    "print(evaluate(tree_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8ecc1bf-cc04-495b-ac2e-b95677b29f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results with Random Forest Classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       393\n",
      "           1       1.00      1.00      1.00       221\n",
      "\n",
      "    accuracy                           1.00       614\n",
      "   macro avg       1.00      1.00      1.00       614\n",
      "weighted avg       1.00      1.00      1.00       614\n",
      "\n",
      "\n",
      "Test Results with Random Forest Classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87       107\n",
      "           1       0.70      0.66      0.68        47\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.78      0.77      0.77       154\n",
      "weighted avg       0.81      0.81      0.81       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Results with Random Forest Classification')\n",
    "print(evaluate(forest_model, X_train, y_train))\n",
    "\n",
    "print('\\nTest Results with Random Forest Classification')\n",
    "print(evaluate(forest_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5dae1-e189-4934-8d33-293f6ffe4767",
   "metadata": {},
   "source": [
    "Tree based algorithms seem to have overfitted. Logistic Regression has the optimal performance among these 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef715f8-d237-495b-9245-76d30ab3d4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
