{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-7FERTVaJoj"
   },
   "source": [
    "<img src=\"https://cellstrat2.s3.amazonaws.com/PlatformAssets/bluewhitelogo.svg\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "# ML Tuesdays - Session 4\n",
    "## Deep Learning Track\n",
    "### CNN Transfer Learning Exercise\n",
    "\n",
    "Train a simple neural network in PyTorch to classify images of the CIFAR-10 dataset using CNNs.\n",
    "\n",
    "### Guidelines\n",
    "1. Use the `PyTorch 1.9` kernel in CellStrat Hub.\n",
    "2. The notebook has been split into multiple steps. Complete the code wherever `# _____ TO-DO _____` is mentioned.\n",
    "3. Here are a few references for you to look at to complete this exercise:\n",
    "    1. [Image Classification with PyTorch Webinar (Practical)](https://youtu.be/Dm1u2xwwSbQ)\n",
    "    2. [CNN Overview (Theory)](https://www.youtube.com/watch?v=IavC1j_A1F4)\n",
    "4. Make use of the docstrings of the functions and classes using the `shift+tab` shortcut key.\n",
    "5. Refer the internet for any extra help needed or just ping anyone from the team on discord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wlzhfoSaJol"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkIegVPUaJoy"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-09 12:04:05--  https://storage.googleapis.com/themightypublicbucket/data.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.16.128, 172.217.0.48, 172.217.1.208, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.16.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2022-02-09 12:04:05 ERROR 403: Forbidden.\n",
      "\n",
      "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n",
      "rm: cannot remove 'data.zip': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://cellstrat-public.s3.amazonaws.com/workshop-files/data_cats_dogs.zip\n",
    "!unzip data_cats_dogs.zip\n",
    "!rm data_cats_dogs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may explore the `data` folder and inspect the dataset before proceeding further.\n",
    "\n",
    "* There are 2000 Training Images, 1000 for each of the two classes\n",
    "* There are 1000 Validation Images, 500 for each of the two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1cnGp_DaJo1"
   },
   "source": [
    "### Loading the Dataset\n",
    "Your Directory Structure of cats and dogs should be like this.\n",
    "```\n",
    "data\n",
    "    train\n",
    "        |__ cat\n",
    "                |__ cat.1.jpg\n",
    "                |__ cat.2.jpg\n",
    "        |__ dog\n",
    "                |__ dog.1.jpg\n",
    "                |__ dog.2.jpg\n",
    "    validation\n",
    "        |__ cat\n",
    "                |__ cat.1.jpg\n",
    "                |__ cat.2.jpg\n",
    "        |__ dog\n",
    "                |__ dog.1.jpg\n",
    "                |__ dog.2.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BsM7bZQaJo2"
   },
   "source": [
    "In the next few cells you need apply a chain of transformations and load the ataset and create the DataLoaders.\n",
    "\n",
    "TO-DO:\n",
    "1. Use transforms.Compose to add image augmentations but the last two should be Resizing to 256x256 and converting to Tensor. \n",
    "\n",
    "For example:\n",
    "```python\n",
    "augmentations = transforms.Compose([transforms.RandomHorizontalFlip(),  \n",
    "                                    #...add more such augmentations.., \n",
    "                                    transforms.Resize((256,256)), \n",
    "                                    transforms.ToTensor()])\n",
    "```\n",
    "2. Create the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EryxMZy5aJo3"
   },
   "outputs": [],
   "source": [
    "# _____ TO-DO _____\n",
    "# Create the Chained Transformations\n",
    "augmentations = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHe8CQsCaJo-"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset from the folder and apply the transformations\n",
    "train_data = datasets.ImageFolder('data/train/', transform=augmentations)\n",
    "val_data = datasets.ImageFolder('data/validation/', transform=augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oi5Gjg9KaJpJ"
   },
   "outputs": [],
   "source": [
    "# _____ TO-DO _____\n",
    "# Create a dataloader for the dataset\n",
    "train_loader = None\n",
    "val_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keLCMniaaJpV"
   },
   "source": [
    "## Model\n",
    "Use transfer learning to train a binary image classifier to recognize cats and dogs. Remember that its a binary classification problem so the final output features should be equal to 1.\n",
    "\n",
    "Steps / TO-DO:\n",
    "1. Load a pretrained model from torchvision and make sure to set `pretrained=True` while loading the model. You can check the [available models here](https://pytorch.org/docs/stable/torchvision/models.html#classification)\n",
    "2. Freeze the Model Params\n",
    "3. Override the final classification block of layers with your own `nn.Sequential` layers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaIk4A9YaJpX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _____ TO-DO _____\n",
    "# Load the pretrained model\n",
    "model = None\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-bH49xQaJpe"
   },
   "outputs": [],
   "source": [
    "# Freeze the model\n",
    "for param in model.parameters():\n",
    "    # _____ TO-DO _____\n",
    "    # set the requires_grad property to False for param\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pnkmwa1aJpl"
   },
   "outputs": [],
   "source": [
    "# _____ TO-DO _____\n",
    "# Override the final block with Sequential layers and the final output as 1 with a sigmoid activation at the end\n",
    "model.fc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfgJURUsaJpr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view the updated model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msTSmZjbaJpw"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48yjMf_raJpw"
   },
   "source": [
    "### Define the Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eme_jAUsaJpy"
   },
   "outputs": [],
   "source": [
    "# Create the Loss\n",
    "criterion = nn.BCELoss()\n",
    "# Create the optimizer by passing only the last block of layers' parameters for optimization\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doZTQbSLaJp2"
   },
   "source": [
    "### Define the Training Loop\n",
    "\n",
    "As we have very less data, we would instead write a training loop without a validation step. We will use the test_data for separately evaluating the model.\n",
    "\n",
    "Complete the training function below.\n",
    "\n",
    "TO-DO:\n",
    "1. Complete the Training Loop\n",
    "    1. Pass the input through the model to get the output\n",
    "    2. Calculate Loss. Make sure\n",
    "        * The input of criterion is squeezed\n",
    "        * The target of criterion is of type float\n",
    "    3. Backpropagate\n",
    "    4. Optimize\n",
    "2. Complete the Validation Loop\n",
    "    1. Pass the input through the model to get the output\n",
    "    2. Calculate Loss. Make sure\n",
    "        * The input of criterion is squeezed\n",
    "        * The target of criterion is of type float\n",
    "    3. Backpropagate\n",
    "    4. Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGxtQQimaJp3"
   },
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          criterion,\n",
    "          optimizer, \n",
    "          device='cpu', \n",
    "          nb_epochs=2,\n",
    "          print_every=100):\n",
    "    \n",
    "    # push to model to the device (CUDA or CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # start epoch\n",
    "    for current_epoch in range(nb_epochs):\n",
    "        \n",
    "        print('Started Epoch {}...\\n'.format(current_epoch+1))\n",
    "        \n",
    "        # TRAIN\n",
    "        \n",
    "        # set the model to train\n",
    "        model.train()\n",
    "        \n",
    "        # loop over the batches of the train loader\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # move the data to selected device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # set the optimizer to zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # _____ TO-DO _____\n",
    "            # pass the inputs through the model\n",
    "            outputs = None\n",
    "            \n",
    "            # _____ TO-DO _____\n",
    "            # calculate loss\n",
    "            loss = None\n",
    "            \n",
    "            # _____ TO-DO _____\n",
    "            # backpropagate\n",
    "            \n",
    "            # _____ TO-DO _____\n",
    "            # optimize\n",
    "            \n",
    "            # print the losses\n",
    "            if i % print_every == 0:\n",
    "                print('Epoch {} Step {} Loss {}'.format(current_epoch+1, i, loss.item()))\n",
    "                \n",
    "        # VALIDATION\n",
    "        \n",
    "        # set the model to evaluation\n",
    "        model.eval()\n",
    "        \n",
    "        # we don't have to calculate gradients during validation\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            val_losses = []\n",
    "            \n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                # move the data to selected device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # _____ TO-DO _____\n",
    "                # pass the inputs through the model\n",
    "                outputs = None\n",
    "                \n",
    "                # _____ TO-DO _____\n",
    "                # calculate loss\n",
    "                loss = None\n",
    "                \n",
    "                # append the losses\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "            print('\\nValidation Loss {}'.format(sum(val_losses)/len(val_losses)))\n",
    "            \n",
    "        print('\\nEnd of Epoch {}\\n\\n'.format(current_epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device automatically for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLrKiKtMaJp8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the Model\n",
    "train(model, train_loader, val_loader, criterion, optimizer, device=device, nb_epochs=3, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G02VNXaGaJqE"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtfOEbs7aJqF"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoVUNgFPaJqK"
   },
   "source": [
    "## Inference\n",
    "Create a `predict()` function to take an image path as input and return Dogs or Cats as the output\n",
    "\n",
    "Steps / TO-DO:\n",
    "1. Read the Image using PIL\n",
    "2. Transform the image into a tensor using `transforms.ToTensor()`\n",
    "3. Forward pass the image_tensor through the model\n",
    "4. Return Cats or Dogs based if output is lesser or greater than 0.5 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDwS9rNYaJqL"
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model, device='cpu'):\n",
    "    \n",
    "    # _____ TO-DO _____\n",
    "    # Read the image with PIL\n",
    "    image = None\n",
    "    \n",
    "    # _____ TO-DO _____\n",
    "    # Create a transformation called tensorify to convert an image to a tensor\n",
    "    tensorify = None\n",
    "    image_tensor = tensorify(image)\n",
    "    \n",
    "    # Unsqeeze image_tensor to reshape to [1, n_channels, height, width]\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    # set the model to evaluation mode and push to device\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # mount input to the appropriate device\n",
    "        x = image_tensor.to(device)\n",
    "        \n",
    "        # _____ TO-DO _____\n",
    "        # Make prediction\n",
    "        output = None\n",
    "        print('Result:', output.item())\n",
    "        \n",
    "        # _____ TO-DO _____\n",
    "        # Create a condition that if output.item() is less than 0.5 return 'Cat'\n",
    "        # else return 'Dog'\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfBMQrmgaJqR"
   },
   "outputs": [],
   "source": [
    "# test the function on some images\n",
    "predict('dog.jpg', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyClXZNLaJqX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyTorch 1.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
